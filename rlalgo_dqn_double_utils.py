def _get_target(
    critic_head,
    tar_critic_head,
    next_obs,
    reward,
    dw,
    gamma
):
    ## ---- Double DQN modification, the next action is generated by the q and then evaluated by the target critic, to reduce q-value overestimation
    next_action = critic_head.forward(obs=next_obs).argmax(dim=1, keepdim=True).detach()
    max_next_q_a = tar_critic_head.forward(obs=next_obs).gather(1, next_action.long())

    return reward + gamma * (1-dw) * max_next_q_a